{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Package: `pandas`\n",
        "The basic data structure for `pandas` is `pandas.DataFrame`. You may treat it as a generalized version of tables.\n",
        "\n",
        "To use `pandas`, we just import it. In most cases you would like to use the alias `pd`."
      ],
      "id": "3ffe1643"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "import pandas as pd"
      ],
      "id": "cc8ea638",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since `DataFrame` is more like a table, the biggest questions here is not to do computations (which is still very important), but to retrieve, search, sort, merge, etc.. those data. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Basic `pandas`\n",
        "\n",
        "###  `Series` and `DataFrame`\n",
        "A *Series* is a 1-d array-like object which has index. The default index is starting from `0`. You may change the index to be something assigned by you. Thus it can be treated as a generalization of a `dict`."
      ],
      "id": "a3e7d414"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import pandas as pd"
      ],
      "id": "9e2f1e01",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "obj = pd.Series([3, 1, 2, 4])\n",
        "obj"
      ],
      "id": "5f607969",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "obj2 = pd.Series([3, 1, 2, 4], index=['a', 'b', 'c', 'd'])\n",
        "obj2"
      ],
      "id": "76a84a01",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data3 = {'a': 3, 'b': 1, 'c': 2, 'd': 4}\n",
        "obj3 = pd.Series(data3)\n",
        "obj3"
      ],
      "id": "9856c4fb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A *DataFrame* represents a rectangular table of data and contains an ordered collection of columns, each of which can be a different value type. The DataFrame has both a row and column index; it can be thought of as a dict of Series all sharing the same index. When displaying a DataFrame, we may use `.head()` to just display the first few rows for efficicy. "
      ],
      "id": "e70710fa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {'a': [1, 2, 3, 4, 5, 6, 7],\n",
        "        'b': [1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1],\n",
        "        'c': ['a', 'b', 'c', 'd', 'e', 'f', 'g']}\n",
        "df = pd.DataFrame(data)\n",
        "df.head()"
      ],
      "id": "b4579d0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decorations\n",
        "A `Series` or a `DataFrame` might have named row indexes and column names. I collect some tools for you to play with them and list them below.\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# Setting when creating\n",
        "We may use the setting `columns=` or `index=` to change the column names and the index names. See the following example."
      ],
      "id": "be6a1c1f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
        "                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n",
        "                    columns=['one', 'two', 'three', 'four'])\n",
        "data"
      ],
      "id": "d72dbfa0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# `.rename()`\n",
        "We may use the `.rename()` method. Note that by default the return value of this method is a copy and it won't affect the original `DataFrame`. The arguments can be in many different formats. Please see [the official document](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html) for more details.\n",
        "\n",
        "If you want to directly make the change, please use the argument `inplace=True`.\n",
        "\n",
        "The following example shows the standard way to rename."
      ],
      "id": "583a6908"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.DataFrame(np.arange(16).reshape((4, 4)))\n",
        "df.rename(columns={0: 'zero'}, index={2: 'two'})"
      ],
      "id": "9920bc5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However the orginal `df` is not affected."
      ],
      "id": "68143bab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df"
      ],
      "id": "30f9b00f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you would like to change the original `df`, you may either set `df = df.rename(columns={0: 'zero'}, index={2: 'two'})`, or "
      ],
      "id": "69971049"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.rename(columns={0: 'zero'}, index={2: 'two'}, inplace=True)\n",
        "df"
      ],
      "id": "747d726e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# Set a column to be the index by `.set_index()`\n",
        "\n",
        "The title is all. A few remarks:\n",
        "\n",
        "1. You may set multiple columns to be the index. In this case, what you get is a multi-index system (which is also called Hierarchical indexing). We will talk about this later in @sec-hierindexing.\n",
        "2. The argument `drop` is used to control whether the column is deleted after you set it to be the index. The default setting is `True`.\n",
        "3. The argument `append` is used to control whether the column you choose is appended to the exsiting index to form a multi-index system. The default is `False`.\n",
        "4. The argument `inplace` is used to control whether you want to make the change inplace. The default is `False`.\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# Reset the index by `.reset_index()`\n",
        "\n",
        "The title is all. A few remarks:\n",
        "\n",
        "1. The new index is integers starting from `0`.\n",
        "2. `drop` is an argument to control whether the original index is dropped or added back to the `DataFrame` as a column. The default is `False`, which means that by default the original index will be added back to the `DataFrame`. \n",
        ":::\n",
        "\n",
        "### Look at the `DataFrame`\n",
        "The following methods can be used to look at the `DataFrame`. Their syntax is very simple. Please try them by yourselves.\n",
        "\n",
        "- `.head()`: show the first few rows.\n",
        "- `.tail()`: show the last few rows.\n",
        "- `.describe()`: show the basic statistics of each columns.\n",
        "\n",
        "These are methods for `Series` which might be helpful to understand the data. \n",
        "\n",
        "- `.unique()`\n",
        "- `.value_counts()`\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# An example\n"
      ],
      "id": "19de354b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'a': [1, 2, 3, 1, 2, 2, 1, 1, 1],\n",
        "                   'b': [3, 1, 1, 2, 4, 5, 2, 1, 3]})\n",
        "df.head(3)"
      ],
      "id": "ad9337e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.tail()"
      ],
      "id": "8c12bc8d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.describe()"
      ],
      "id": "4eafdde2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df['a'].unique()"
      ],
      "id": "1fc3d8aa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df['b'].value_counts()"
      ],
      "id": "78da8409",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Indexing\n",
        "The act of selecting rows or columns to access from a dataframe or series is called *indexing*. There are many different ways to index in `pandas`. We will only cover the most popular ones.\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "There is the same copy and view issue with `pandas` as in `numpy`. However it is more complicated and more inconsistent. Please check the official documents for more details and do more experiments before implementing the codes. Usually if your code is ambiguous, you might see the infamous `SettingWithCopyWarning` warning.\n"
      ],
      "id": "673e418b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: true\n",
        "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
        "df[df['a']==3]['b'] = 3"
      ],
      "id": "7cb170ce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that `pandas` is testing a `copy-on-write` feature to fix the issue. The feature can be simlified as \"any `DataFrame` or `Series` derived from another in any way always behaves as a copy\". Please keep an eye on the updates about when the feature will be fully implemented in `pandas`.\n",
        ":::\n",
        "\n",
        "\n",
        "### `[]`\n",
        "\n",
        "::: {.callout-note collapse=true}\n",
        "## `Series[]`"
      ],
      "id": "619df215"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "from IPython.display import Markdown\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "table = [['`Series[label]`', 'scalar value'],\n",
        "         ['`Series[list of labels]`', '`Series` corresponding to labels'],\n",
        "         ['`Series[slice]`', '`Series` corresponding to the slice'],\n",
        "         ['`Series[boolean vector]`', '`Series` corresponding to the boolean vector']]\n",
        "        #  ['DataFrame', '`dateframe[colname]`', '`Series` corresponding to colname'],\n",
        "        #  ['DataFrame', '`dataframe[list of colnames]`', '`DataFrame` corresponding to colnames']]\n",
        "# table = {\"Object Type\": ['Series', 'DataFrame'],\n",
        "        #  \"Selection\": ['`series[label]`', '`dateframe[colname]`'],\n",
        "        #  \"Return Value Type\": ['scalar value', '`Series` corresponding to colname']}\n",
        "# Markdown(pd.DataFrame(table))\n",
        "# df = pd.DataFrame(table)\n",
        "Markdown(tabulate(table, headers=[\"Input value type\",\n",
        "                                  \"Return Value Type\" ]))"
      ],
      "id": "ec5208d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. For `Series`, values are accessed by labels, not positions. Since `Series` are usually considered as a column, you may think these labels as row indexes. \n",
        "\n",
        "2. When using slice, things becomes more complicated. There are two ways of using slice. You may either slice by positions, or slice by labels. The main differences between them is that:\n",
        "\n",
        "- slice by positions `Series[i:j]` doesn't contain the last index `Series[j]`;\n",
        "- slice by labels `Sereies[I:J]` contains the last label `Series[J]`.\n",
        "\n",
        "3. Sometimes the labels of a series are integers, but different than the position indexes. In `pandas 1.5.1`, slice by positions takes priority. However the whole scenario is very confusing, and this will be changed in future versions. In this cases it is recommanded to use `.loc` and `.iloc`.  \n",
        "\n",
        "4. When indexing using boolean vector, the vector should be of the same length as the `Series`. In other words, it works as the boolean bector shows which row is selected.\n",
        "\n",
        "See some examples below.\n",
        "\n",
        "\n",
        "::: {#exm-}"
      ],
      "id": "1a7df2f4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "example = pd.Series({'a': 1.1, 'b': 2.2, 'c': 3.3, 'd': 4.4})\n",
        "example"
      ],
      "id": "74984744",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example['b']"
      ],
      "id": "dc830585",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example[['b', 'a']]"
      ],
      "id": "42fb5ce1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example[0:2]"
      ],
      "id": "3c0e60a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example['a':'c']"
      ],
      "id": "afbdd663",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example[[True, False, True, False]]"
      ],
      "id": "20456e0a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=true}\n",
        "## `DataFrame[]`"
      ],
      "id": "c374f113"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "from IPython.display import Markdown\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "table = [[ '`DataFrame[colname]`', 'The column corresponding to colname as a `Series`'],\n",
        "         ['`DataFrame[list-of-colnames]`', 'The columns of `DataFrame` corresponding to colnames'],\n",
        "         ['`DataFrame[slice]`', 'The rows of `DataFrame` corresponding to the slice' ],\n",
        "         ['`DataFrame[boolean list]`', '`DataFrame` corresponding to the boolean list']]\n",
        "# table = {\"Object Type\": ['Series', 'DataFrame'],\n",
        "        #  \"Selection\": ['`series[label]`', '`dateframe[colname]`'],\n",
        "        #  \"Return Value Type\": ['scalar value', '`Series` corresponding to colname']}\n",
        "# Markdown(pd.DataFrame(table))\n",
        "# df = pd.DataFrame(table)\n",
        "Markdown(tabulate(table, headers=[\"Input value type\",\n",
        "                                  \"Return Value Type\" ]))"
      ],
      "id": "9e029646",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Slice for `DataFrame` behaves exactly like slice for `Series`, that it is selecting rows, and it works for both labels and positions. Similarly, slicing by positions are not recommended and might be deprecated in the future. \n",
        "2. On the other hand side, selecting rows are usually related to querying. Therefore it is better not to focus on slicing.\n",
        "3. Inside `[]`, one column name and a list of columna names will result totally different objects: one is a `Series` and the other is a `DataFrame`. \n",
        "4. In prior versions, using `[list-of-colnames]` would work as long as *at least* 1 of the keys was found (otherwise it would raise a `KeyError`). This behavior was changed and will now raise a `KeyError` if at least one label is missing. The recommended alternative is to use `.reindex()`.\n",
        "5. When indexing using boolean vector, the vector should be of the same length as the number of rows of the `DataFrame`. In other words, it works as the boolean bector shows which row is selected.\n",
        "6. Using `[]` for `DataFrame` cannot give you a single value, since what are inside `[]` is always treated as a row index or a column index. If you want to get access to the value of a single cell by both row index and column index, use other method like `.loc[]`.\n",
        "7. If the column name is eligible for attributes, you may also use `df.a` to represent `df['a']` for simplicity.\n",
        "\n",
        "::: {#exm-}"
      ],
      "id": "1dd39c90"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "example = pd.DataFrame({'a': [1.1, 2.2], 'b': [2.2, 3.3], 'c': [3.3, 4.4]})\n",
        "example"
      ],
      "id": "39657e32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example['a']"
      ],
      "id": "562f064c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example.a"
      ],
      "id": "a1e77830",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example[['a']]"
      ],
      "id": "626e82f8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example[0:1]"
      ],
      "id": "2b0d2439",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example[[False, True]]"
      ],
      "id": "8e40ddec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### `.loc[]` and `.iloc[]`\n",
        "\n",
        "`[]` contains several different types of ways to access data. `.loc[]` and `.iloc[]` are more specific. \n",
        "\n",
        "- `.loc[]` is to use labels to access data.\n",
        "- `.iloc[]` is to use positions to access data.\n",
        "\n",
        "\n",
        ":::{.callout-note collapse=true}\n",
        "## Notes for `.loc[]` and `.iloc[]`\n",
        "\n",
        "1. When there is only one index is specified, it is refered to rows. \n",
        "2. When using both indexes, the first is row index and the second is column index.\n",
        "3. When selecting all rows/columns, you may put `:` in the corresponding place.\n",
        "4. `df.loc[1, 'a']` refers to the cell in the DataFrame `df` whose row index is `1` and column index is `a`. `df[1, 'a']` refers to the column in the DataFrame `df` whose column name is `(1, 'a')`.\n",
        "5. Many other small details are very similar to `[]`. For example, pay attention to the differences between `df.loc[:, 'a']` and `df.loc[:, ['a']]`.\n",
        "\n",
        "\n",
        "::: {#exm-}\n"
      ],
      "id": "f06861e3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "example = pd.DataFrame({'a': [1.1, 2.2], 'b': [2.2, 3.3], 'c': [3.3, 4.4]})\n",
        "example"
      ],
      "id": "b179064e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example.loc[1]"
      ],
      "id": "8b2d16cf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example.loc[:, 'a']"
      ],
      "id": "cf18cfb5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example.loc[1, 'a']"
      ],
      "id": "99236505",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example.iloc[0:1, 0:2]"
      ],
      "id": "053acfc0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example.iloc[1, 0:2]"
      ],
      "id": "f286abfe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example.iloc[[1], 0:2]"
      ],
      "id": "0327d13d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Boolean indexing\n",
        "Let `df` be a `DataFrame`. Assume that `boo` is boolean vector of the dimension same to the number of rows of `df`, then we can use `df[boo]` to filter data: all rows with `True` will be selected. The syntax is similar to the boolean indexing in `numpy`.\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# The basic usage of boolean indexing"
      ],
      "id": "af156d2b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.DataFrame(np.random.randn(8, 4),\n",
        "                  index=pd.date_range('1/1/2023', periods=8),\n",
        "                  columns=['A', 'B', 'C', 'D'])\n",
        "df"
      ],
      "id": "cebb0147",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[df['A']>0]"
      ],
      "id": "6e945b84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get the boolean vector, we may directly compute logic expression using columns of `df`. The previous example is of this kind.\n",
        "\n",
        "You may write complicated expressions. The operators are:\n",
        "\n",
        "- `|` for or\n",
        "- `&` for and\n",
        "- `~` for not\n",
        "\n",
        "Note that parentheses **must** be used to ensure a correct result. Please see the following example."
      ],
      "id": "3e7878d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[(df['A'] > 1) & (df['B'] < 3)]"
      ],
      "id": "0e5d971a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "<!-- One method that is usually use is `.isin()` method. This is used to check whether the entry of the `Series` belongs to a `list`. -->\n",
        "\n",
        "There are many methods and functions that can create boolean vectors. We will introduce them when we need them.\n",
        "\n",
        "\n",
        "\n",
        "### `.query()`\n",
        "`DataFrame` has a `.query()` method that allows filtering using an expression instead of a boolean vector. This method uses a different approach from the point of programming language. From the point of users, you are free to choose between `.query()` and boolean indexing to filter data.\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# Here are examples of `.query()`."
      ],
      "id": "ebbd89aa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.DataFrame({'A': [1,2,3], 'B': [3,2,1], 'C': [5,4,3]})\n",
        "df"
      ],
      "id": "4819f628",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.query('A<B and B<C')"
      ],
      "id": "c41f82fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It can be simplified as follows:"
      ],
      "id": "182354a2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.query('A<B<C')"
      ],
      "id": "03c8bbdb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the same as the following code."
      ],
      "id": "ae50093d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[(df['A']<df['B']) & (df['B']<df['C'])]"
      ],
      "id": "8b602a80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that `.query()` does not require the usage of parentheses. It also use English like `or`/`and`/`not` for `|`/`&`/`~`.\n"
      ],
      "id": "fb51b6e6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.query('A in C')"
      ],
      "id": "7a1df823",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.query('A not in C')"
      ],
      "id": "b7a96969",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.query('A not in C and A<B')"
      ],
      "id": "291b11b9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.query('[1,2] in B')"
      ],
      "id": "b20bed37",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "### Reindex\n",
        "\n",
        "`.reindex()` is a data alignment method in `pandas`. To reindex means to conform the data to match a given set of labels along a particular axis. This accomplishes several things:\n",
        "\n",
        "- Reordering the existing data to match a new set of labels\n",
        "- Inserting missing value (`NaN`) markers in label locations where no data for that label existed\n",
        "\n",
        "Here is a simple example:\n"
      ],
      "id": "17987e1a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
        "                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n",
        "                    columns=['one', 'two', 'three', 'four'])\n",
        "data"
      ],
      "id": "805c7a4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.reindex(index = ['Colorado', 'Arkansas', 'New York'],\n",
        "             columns = ['three', 'five', 'one'])"
      ],
      "id": "2a749870",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the first glance, `.reindex()` behave the same as other indexing methods. Here are a few differences:\n",
        "\n",
        "- The purpose of indexing methods is to select/filter data, while the purpose of reindex is to make the data in a very specific form.\n",
        "- When dealing with non-existent indexes/columns, most other indexing methods will return error or warning, while `.reindex()` can handle it automatically.\n",
        "- The default setting of `.reindex()` is to return a copy. This setting can be changed by the argument `copy=False`. \n",
        "\n",
        "For more details please see the [official guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#reindexing). \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!-- \n",
        "\n",
        "- Series indexing `(obj[...])` works analogously to NumPy array indexing, except you\n",
        "can use the Series’s index values instead of only integers. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- We can use logical expresssion to filter DataFrame.\n"
      ],
      "id": "abbb1aba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
        "                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n",
        "                    columns=['one', 'two', 'three', 'four'])\n",
        "data[data['one']>5]"
      ],
      "id": "14029f0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `.loc`, `.iloc`"
      ],
      "id": "73657be7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
        "                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n",
        "                    columns=['one', 'two', 'three', 'four'])\n",
        "print(data.loc['Colorado', ['two', 'three']])\n",
        "print(data.iloc[2, [3, 0, 1]])"
      ],
      "id": "69cfc2d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Slicing with labels behaves differently than normal Python slicing in that the endpoint is inclusive. "
      ],
      "id": "148c22b7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "obj = pd.Series(np.arange(4.), index=['a', 'b', 'c', 'd'])\n",
        "obj['b':'c']"
      ],
      "id": "4a8af03b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Reindex `.reindex()`:\n",
        "\n",
        "\n",
        "::: {.callout-note}\n",
        ":::\n",
        " -->\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Updating data\n",
        "- Assign values to a column of a DataFrame will update that column. If the column doesn't exist, new column will be created. This is called *enlargement*. \n",
        "- When assign values with non-existent row index, that part of the data will be discarded. \n",
        "- When using `.loc`, a `DataFrame` can be enlarged on either axis.\n",
        "- Any time if there are no values with a specific column and row, it will show as `NaN`. \n",
        "<!-- - When locating data using indexes, duplicate labels will return all results. -->\n",
        "\n",
        "::: {#exm-}"
      ],
      "id": "9deaa80a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {'a': [1, 2, 3, 4],\n",
        "        'b': [1.1, 2.1, 3.1, 4.1],\n",
        "        'c': ['a', 'b', 'c', 'd']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "newcol = {1: 'good', 3: 'better', 5: 'best'}\n",
        "df['d'] = pd.Series(newcol)\n",
        "df"
      ],
      "id": "12c82d88",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Data cleaning\n",
        "\n",
        "### Handling Missing Data\n",
        "\n",
        "- `np.nan`, `pd.NA`\n",
        "- `pd.isnull()`, `np.isnan()`\n",
        "- `.dropna()`, `.fillna()`\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# `.dropna()` example"
      ],
      "id": "5b5ad10a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.DataFrame([[1., 6.5, 3.], [1., np.nan, np.nan], \n",
        "                     [np.nan, np.nan, np.nan], [np.nan, 6.5, 3.]])\n",
        "data"
      ],
      "id": "f18a417b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.dropna()"
      ],
      "id": "fbbe68b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.dropna(how='all')"
      ],
      "id": "3bb76e54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data[4] = np.nan\n",
        "data"
      ],
      "id": "833169e8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.dropna(axis=1, how='all')"
      ],
      "id": "6f72ef8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.dropna(thresh=2)"
      ],
      "id": "3fba5c64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# `.fillna()` example\n"
      ],
      "id": "10a38368"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.fillna(0)"
      ],
      "id": "dccdf611",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.fillna({1: 0.5, 2: -0.1})"
      ],
      "id": "c494a32c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# Arithmetic and Data Alignment\n",
        "\n",
        "Elements of the same index and columns will be computed. By default, if any entry is `nan`, the answer will be `nan`. You may use `fill_value` argument to fill the empty slots. Please see the following example.\n"
      ],
      "id": "d90b49e5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)), columns=list('abcd'))\n",
        "df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)), columns=list('abcde'))\n",
        "df2.loc[1, 'b'] = np.nan\n",
        "\n",
        "df1.add(df2, fill_value=0)"
      ],
      "id": "b653cc57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Relatedly, when reindexing a Series or DataFrame, you can also specify a `fill_value`.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "### Handling duplicates\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# `.drop_duplicates()` example"
      ],
      "id": "c60c4b93"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'], \n",
        "                     'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
        "data.drop_duplicates(['k1'], keep='last')"
      ],
      "id": "8984006b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "### Drop data\n",
        "You may use `.drop()` to drop columns or rows.\n",
        "\n",
        "1. If you directly apply `.drop()` to an index, that index is considered as a row index.\n",
        "2. To drop a column, you need to specify the argument `columns=`.\n",
        "3. There is still the `inplace=` issue.\n",
        "\n",
        "### String Manipulation\n",
        "\n",
        "When the column `Series` is of type `str`, all methods in `pd.Series.str` will be applied to each entry of the Series.\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# Some basic examples"
      ],
      "id": "55447316"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "s = pd.Series([\"A \", \" B \", \"C\", \"Aaba\", \" Baca \", np.nan, \"CABA\", \"dog\", \"cat\"])\n",
        "s"
      ],
      "id": "2f6f3161",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s.str.lower()"
      ],
      "id": "4d5c751c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s.str.split('a')"
      ],
      "id": "74be7067",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s.str.len()"
      ],
      "id": "73a26673",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s.str.strip()"
      ],
      "id": "b93b7ab1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s.str.replace(\"A\", '1')"
      ],
      "id": "4ad1a6c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {#exm-}\n",
        "We could also use `.str` to play with column names and row indexes."
      ],
      "id": "076738b3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.DataFrame(np.random.randn(3, 2),\n",
        "                  columns=[\" Column A \", \" Column B \"], index=range(3))\n",
        "\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "df"
      ],
      "id": "c5d484ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "String methods are usually used with regular expressions. For more details please see @sec-re.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!-- \n",
        "\n",
        "- `pd.Series.map()`, `pd.DataFrame.apply()`\n",
        "\n",
        "\n",
        "::: {#exm-}"
      ],
      "id": "0a7e55bd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon',\n",
        "                     'Pastrami', 'corned beef', 'Bacon',\n",
        "                     'pastrami', 'honey ham', 'nova lox'],\n",
        "                     'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
        "\n",
        "meat_to_animal = {\n",
        "    'bacon': 'pig',\n",
        "    'pulled pork': 'pig',\n",
        "    'pastrami': 'cow',\n",
        "    'corned beef': 'cow',\n",
        "    'honey ham': 'pig',\n",
        "    'nova lox': 'salmon'\n",
        "    }\n",
        "\n",
        "data['animal'] = data['food'].str.lower().map(meat_to_animal)\n",
        "\n",
        "data['food'].map(lambda x: meat_to_animal[x.lower()])"
      ],
      "id": "df1a60ef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "- `replace`\n",
        "- `rename` -->\n",
        "<!-- - `pd.cut(ages, bins)` -->\n",
        "<!--- `describe`\n",
        "- `permutation`\n",
        "- `sample`\n",
        "- dummy variables -->\n",
        "\n",
        "\n",
        "## Data Wrangling\n",
        "\n",
        "### Tidy data\n",
        "\n",
        "\n",
        "The same underlying data can be represented in multiple ways. To better study the data, it is better to make these data *tidy*.\n",
        "\n",
        "::: {#def-}\n",
        "A dataset is *tidy* if\n",
        "\n",
        "1. Each variable have its own column.\n",
        "2. Each observation have its own row.\n",
        "3. Each value have its oven cell.\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# Typical examples of tidydata\n",
        "\n",
        "These `DataFrame` are provided by `tidyr`. We will talk about them again when we get to R. These tables can be downloaded by clicking the names.\n",
        "\n",
        "\n",
        "1. [`table1`](assests/datasets/table1.csv)\n"
      ],
      "id": "a1827f48"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import pandas as pd\n",
        "table1 = pd.read_csv('assests/datasets/table1.csv', index_col='Unnamed: 0')\n",
        "table1"
      ],
      "id": "52fef3ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. [`table2`](assests/datasets/table2.csv)"
      ],
      "id": "d0705faa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import pandas as pd\n",
        "table2 = pd.read_csv('assests/datasets/table2.csv', index_col='Unnamed: 0')\n",
        "table2"
      ],
      "id": "6d96b368",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. [`table3`](assests/datasets/table3.csv)"
      ],
      "id": "6b760da9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import pandas as pd\n",
        "table3 = pd.read_csv('assests/datasets/table3.csv', index_col='Unnamed: 0')\n",
        "table3"
      ],
      "id": "09605be5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Spread across two `DataFrame`s: [`table4a`](assests/datasets/table4a.csv) and [`table4b`](assests/datasets/table4b.csv):"
      ],
      "id": "14ddcf9b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import pandas as pd\n",
        "table4a = pd.read_csv('assests/datasets/table4a.csv', index_col='Unnamed: 0')\n",
        "table4b = pd.read_csv('assests/datasets/table4b.csv', index_col='Unnamed: 0')\n",
        "table4a"
      ],
      "id": "4346f04d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "table4b"
      ],
      "id": "7ce188c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Among all these `DataFrame`s, only `table1` is tidy.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "These three conditions are interrelated because it is impossible to only satisfy two of the three. In pratical, we need to follow the instructions:\n",
        "\n",
        "1. Put each dataset in a `DataFrame`.\n",
        "2. Put each variable in a column.\n",
        "3. Every row is about one obeservation.\n",
        "\n",
        "*Tidy* data is a consistent way to organize your data. The main advantages are:\n",
        "\n",
        "1. It is one consistent way of storing data. In other words, this is a consistent data structure that can be used in many cases.\n",
        "2. To placing variables in columns enables Python to do vectorized operations.\n",
        "\n",
        "\n",
        "\n",
        "Most datasets are untidy, since tidy data is usually not intuitive for collecting. Therefore raw data which are collected by some naive ideas are usually not tidy. \n",
        "\n",
        "Untidy data are usually:\n",
        "\n",
        "- One variable might be spread across multiple columns.\n",
        "- One observation might be scattered across multiple rows.\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# `.melt()` method\n",
        "\n",
        "A common problem is that the column names are not names of variables, but values of a variable. For example, `table4a` above has columns `1999` and `2000`. These two names are actually the values of a variable `year`. In addition, each row represents two observations, not one."
      ],
      "id": "93e60d17"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "table4a"
      ],
      "id": "479bbf26",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To tidy this type of dataset, we need to gather those columns into a new pair of variables. We need three parameters:\n",
        "\n",
        "- The set of columns that represent values. In this case, those are `1999` and `2000`.\n",
        "- The name of the variable. In this case, it is `year`. \n",
        "-The name of the variable whose values are spread over the cells. In this case, it is the number of `cases`. \n",
        "\n",
        "Then we apply `.melt()`."
      ],
      "id": "c67340f1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "table4a.melt(id_vars=['country'],\n",
        "             value_vars=['1999', '2000'],\n",
        "             var_name='year',\n",
        "             value_name='cases')"
      ],
      "id": "321cc479",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can do the similar thing to `table4b`. "
      ],
      "id": "26312264"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "table4b.melt(id_vars=['country'],\n",
        "             value_vars=['1999', '2000'],\n",
        "             var_name='year',\n",
        "             value_name='population')"
      ],
      "id": "a1f3eec5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-tip}\n",
        "In Python there are multiple different ways to change a wide `DataFrame` to be longer like `.melt()`. Among all of them, `.melt()` is the most common one.\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# `.pivot()` method\n",
        "\n",
        "\n",
        "Another issuse is that an observation is scattered across multiple rows. Take `table2` as an example. \n",
        "\n",
        "An observation is a country in a year, but each observation is spread across two rows."
      ],
      "id": "7bdd1e90"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "table2"
      ],
      "id": "6e181764",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We could apply `.pivot()` to make it tidy. Here we need two arguments.\n",
        "\n",
        "- The column that contains variable names. Here, it’s `type`.\n",
        "- The column that contains values forms multiple variables. Here, it’s `count`.\n"
      ],
      "id": "1612016e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "table2.pivot(index=['country', 'year'], columns='type', values='count')"
      ],
      "id": "e2697689",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- \n",
        "\n",
        "\n",
        "`pivot_wider()` is an updated approach to `spread()`, designed to be both simpler to use and to handle more use cases. We recommend you use `pivot_wider()` for new code; `spread()` isn't going away but is no longer under active development. -->\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# Split and combine columns\n",
        "\n",
        "If we would like to split one columns into multiple columns since there are more than one values in a cell, we could use `Series` string method to split it. \n"
      ],
      "id": "3289176b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "table3['newrate'] = table3['rate'].str.split('/')\n",
        "table3"
      ],
      "id": "0252ea0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we prepare two columns from the beginning, we could directly get two columns. Note that the argument `expand=True` means that we want to get a `DataFrame` by expanding dimensionality. More details can be found [here](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html)."
      ],
      "id": "9d242f9f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "table3[['cases', 'population']] = table3['rate'].str.split('/', expand=True)\n",
        "table3.drop(columns=['rate', 'newrate'], inplace=True)\n",
        "table3"
      ],
      "id": "10d72aa0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly we could also combine columns just as they are strings."
      ],
      "id": "686408f4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "table3['another_rate'] = table3['cases']+'/'+table3['population']\n",
        "table3"
      ],
      "id": "705bf78b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Hierarchical indexing {#sec-hierindexing}\n",
        "Pandas support a more complex indexing system, that the index may have multiple levels. See the following example.\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# An example"
      ],
      "id": "929788fc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.Series(np.random.randn(9),\n",
        "                 index = [['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n",
        "                          [1, 2, 3, 1, 2, 3, 1, 2, 3]])\n",
        "data"
      ],
      "id": "d795de30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You may look at the Series using different levels of indexes."
      ],
      "id": "535f57b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data['a']"
      ],
      "id": "184a97e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.loc[:, 2]"
      ],
      "id": "986be5c7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You may use groupby to group by levels and do calculations related to levels. More `.groupby()` will be discussed in the next section. "
      ],
      "id": "664d8446"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.groupby(level=1).sum()"
      ],
      "id": "6b39eaf0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "From the example above, you may notice that the 2-level hierarchical indexing for a Series works very similar to a DataFrame. In fact, you may translate it back and forth between a 2-level indexing Series and a DataFrame."
      ],
      "id": "29c1d63b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = data.unstack()\n",
        "df"
      ],
      "id": "df92de7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.stack()"
      ],
      "id": "7cb9df06",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For DataFrame the index for both axes can be multiindex. The usual indexing way can be used if you want to start from the first level of the index. The more specific method to extract data is `.xs`.\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# An example"
      ],
      "id": "f43bb6c7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame(\n",
        "    {\n",
        "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
        "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
        "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
        "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
        "    },\n",
        "    index=[0, 1, 2, 3],\n",
        ")\n",
        "\n",
        "df2 = pd.DataFrame(\n",
        "    {\n",
        "        \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n",
        "        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n",
        "        \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n",
        "        \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n",
        "    },\n",
        "    index=[4, 5, 6, 7],\n",
        ")\n",
        "\n",
        "df = pd.concat([df1, df2], keys=['x', 'y'])"
      ],
      "id": "e06a13fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df"
      ],
      "id": "3cfe710c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df['A']"
      ],
      "id": "9705a769",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.loc['x']"
      ],
      "id": "ddf759ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.loc['x',3]"
      ],
      "id": "9666bebc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.xs(3, level=1, drop_level=False)"
      ],
      "id": "8929003b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Combining and Merging Datasets\n",
        "`merge` and `concat` are the two most common ways to combine datasets. \n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# `pd.merge()` function\n",
        "Merge combines datasets by linking rows using one or more keys. This is from relational databases (e.g., SQL-based). \n",
        "\n",
        "Here are some examples. \n",
        "\n",
        "::: {#exm-}"
      ],
      "id": "073df1b0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
        "                    'data1': range(7)})\n",
        "df2 = pd.DataFrame({'key': ['a', 'b', 'd'], 'data2': range(3)})"
      ],
      "id": "2ce1eaa5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The two DataFrames are displayed as follows."
      ],
      "id": "bd743f7d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df1"
      ],
      "id": "31644a20",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df2"
      ],
      "id": "ff7e5d76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.merge(df1, df2, on='key')"
      ],
      "id": "98fda18b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the column names are different in each object, you can specify them separately."
      ],
      "id": "dd85d0eb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df3 = pd.DataFrame({'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
        "                    'data1': range(7)})\n",
        "df4 = pd.DataFrame({'rkey': ['a', 'b', 'd'],\n",
        "                    'data2': range(3)})\n",
        "pd.merge(df3, df4, left_on='lkey', right_on='rkey')"
      ],
      "id": "7fbc4aae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "By default `merge` does an inner join, that the keys in the result are the interesection found in both tables. Below are different types of `merge`. To specify the method for merge, the option is `how`.\n",
        "\n",
        "- `inner`\n",
        "- `left`\n",
        "- `right`\n",
        "- `outer`\n",
        "\n",
        "Let's see the following examples.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {.grid}\n",
        "\n",
        "::: {.g-col-6}"
      ],
      "id": "19c5d2b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df1 = pd.DataFrame({'Key': [1, 2], 'A': [0, 2], 'B': [1, 3]})\n",
        "df1"
      ],
      "id": "fc91413b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.g-col-6}"
      ],
      "id": "015d4640"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df2 = pd.DataFrame({'Key': [1, 3], 'C': [0, 2], 'D': [1, 3]})\n",
        "df2"
      ],
      "id": "8beaf45d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {.grid}\n",
        "\n",
        "\n",
        "::: {.g-col-6}"
      ],
      "id": "7203ab1a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.merge(df1, df2, on='Key', how='inner')"
      ],
      "id": "f4a682a4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "::: {.g-col-6}"
      ],
      "id": "6ba1c071"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.merge(df1, df2, on='Key', how='outer')"
      ],
      "id": "a30b85ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {.grid}\n",
        "\n",
        "\n",
        "::: {.g-col-6}"
      ],
      "id": "c8ed12b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.merge(df1, df2, on='Key', how='left')"
      ],
      "id": "982a949a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.g-col-6}"
      ],
      "id": "7932a13a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.merge(df1, df2, on='Key', how='right')"
      ],
      "id": "c4b60137",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-note}\n",
        "If a key combination appears more than once in both tables, the resulting table will have the Cartesian product of the associated data. Here is a very basic example with one unique key combination."
      ],
      "id": "341e16be"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'],\n",
        "                    'data1': range(6)})\n",
        "df2 = pd.DataFrame({'key': ['a', 'b', 'a', 'b', 'd'],\n",
        "                    'data2': range(5)})\n",
        "pd.merge(df1, df2, on='key', how='left')"
      ],
      "id": "c35b131c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-note} \n",
        "If the merge keys in a DataFrame is in its index instead of column(s), we could pass `left_index=True` or `right_index=True` or both instead of setting `left_on`/`right_on`/`on`.\n",
        ":::\n",
        "\n",
        "\n",
        "::: {#exm-crossexample-deck}\n",
        "If we want to really create a Cartesian product, we may use the option `how='cross'`. For example, we would like to generate a deck of cards, we may use the following codes."
      ],
      "id": "78214e04"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "suit = pd.DataFrame({'suit': ['spades', 'hearts', 'clubs', 'diamonds']})\n",
        "face = pd.DataFrame({'face': list(range(1, 14))})\n",
        "deck = pd.merge(suit, face, how='cross')"
      ],
      "id": "47fe8025",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# `pd.concat()` function\n",
        "The `concat()` function (in the main pandas namespace) performs concatenation operations along an axis while performing optional set logic (union or intersection) of the indexes (if any) on the other axes.  \n"
      ],
      "id": "6bae2c64"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame(\n",
        "    {\n",
        "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
        "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
        "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
        "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
        "    },\n",
        "    index=[0, 1, 2, 3],\n",
        ")\n",
        "\n",
        "df2 = pd.DataFrame(\n",
        "    {\n",
        "        \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n",
        "        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n",
        "        \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n",
        "        \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n",
        "    },\n",
        "    index=[4, 5, 6, 7],\n",
        ")\n",
        "\n",
        "df3 = pd.DataFrame(\n",
        "    {\n",
        "        \"A\": [\"A8\", \"A9\", \"A10\", \"A11\"],\n",
        "        \"B\": [\"B8\", \"B9\", \"B10\", \"B11\"],\n",
        "        \"C\": [\"C8\", \"C9\", \"C10\", \"C11\"],\n",
        "        \"D\": [\"D8\", \"D9\", \"D10\", \"D11\"],\n",
        "    },\n",
        "    index=[8, 9, 10, 11],\n",
        ")\n",
        "\n",
        "pd.concat([df1, df2, df3], keys=['x', 'y', 'z'])"
      ],
      "id": "e54d3169",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The default way of `pd.concat()` is vertically. Note that it will check the column names. If the column names don't match, new columns will be created and `nan` values will be assigned. \n",
        "\n",
        "If you want to concatenate the DataFrame horizontally you need to add `axis=1` option.\n",
        "Similarly, row index will be checked before concatenating. See the following example.\n",
        "\n",
        "::: {#exm-}"
      ],
      "id": "b2720d7f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.concat([df1, df2, df3], axis=1)"
      ],
      "id": "9829162c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {#exm-}\n",
        "Consider the deck example from @exm-crossexample-deck. This time we would like to use `pd.concat()` to get the result."
      ],
      "id": "13bd8379"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "suitlist = ['spades', 'hearts', 'clubs', 'diamonds']\n",
        "facelist = list(range(1, 14))\n",
        "decklist = [pd.DataFrame({'suit': suit, 'face': facelist}) for suit in suitlist]\n",
        "deck = pd.concat(decklist, ignore_index=True)"
      ],
      "id": "765f56d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "## Data Aggregation and Group Operations\n",
        "\n",
        "### split-apply-combine model\n",
        "\n",
        "We would like to apply group operations based on the split-apply-combine model. \n",
        "\n",
        "- In the first stage of the process, data contained in a pandas object is *split* into groups based on one or more keys that you provide. We then use `.groupby(keys)` to perform the split step. The result is a grouped `groupby` object.\n",
        "- Once this is done, a function is *applied* to each group, producing a new value. \n",
        "- Finally the results of all those function applications are combined into a result object. We may apply groupby functions directly as methods to groupby objects.The result is the combined result object.\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# An example"
      ],
      "id": "f6243139"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n",
        "                   'key2' : ['one', 'two', 'one', 'two', 'one'],\n",
        "                   'data1' : np.random.randn(5),\n",
        "                   'data2' : np.random.randn(5)})\n",
        "df"
      ],
      "id": "0251ac76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we want to group `data1` in `df` by `key1`."
      ],
      "id": "5b5a4b6a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grouped = df['data1'].groupby(df['key1'])\n",
        "grouped"
      ],
      "id": "eba19bda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What we get is a groupby object and we could apply group functions to it.\n",
        "\n",
        "The method to look at each group is `.get_group()`."
      ],
      "id": "c15e0102"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grouped.get_group('a')"
      ],
      "id": "2a1116ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We may directly apply some group functions to the groupby object."
      ],
      "id": "bae6b1b7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grouped.mean()"
      ],
      "id": "9e495964",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grouped.size()"
      ],
      "id": "32ef3f19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We could iterate over groups."
      ],
      "id": "c43676e4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for name, group in grouped:\n",
        "    print('name', name)\n",
        "    print('group', group)"
      ],
      "id": "2ad18c9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We could convert the group object into list and dictionary."
      ],
      "id": "f1f8028d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "list(grouped)"
      ],
      "id": "27cf2459",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dict(list(grouped))"
      ],
      "id": "a7b3d7db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "### Built-in aggregation functions\n",
        "\n",
        "The following functions directly work with groupby objects. You may try them by yourselves.\n",
        "\n",
        "- `.describe()`\n",
        "- `.count()`\n",
        "- `.sum()`\n",
        "- `.mean()`\n",
        "- `.median`\n",
        "- `.std()`, `.var()`\n",
        "- `.min()`, `.max()`\n",
        "- `.prod()`\n",
        "- `.first()`, `.last()`\n",
        "<!-- - `.agg()` -->\n",
        "\n",
        "\n",
        "\n",
        "### Function Application and Mapping\n",
        "We may apply functions to each row/column of a `DataFrame`. If the function is a built-in function that is compatible with `DataFrame`, you can directly call the function that it will be applied automatically to each row/column. If it is not, we can call `apply` to get the desired result. \n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# `map`\n",
        "To understand the behaviour of `map`, you may treat it as a loop, through a `Series`. `pandas` goes through each item in the `Series` and perform operations as instructed. If there is a returned value, it will be recorded along the `Sereis`.\n"
      ],
      "id": "4a26f478"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "ind = pd.Series(['Ohio', 'Colorado', 'New York'])\n",
        "ind"
      ],
      "id": "41d09191",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ind.map(lambda x: x[:4].upper())"
      ],
      "id": "1c990fd5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the example we go through each item in `ind`. Each item is a string. We pick the first 4 characters, and change them to be upper case.\n",
        "\n",
        "Note that this operation can also be done by string method. These are two different methods but the results are the same."
      ],
      "id": "9364fae1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ind.str[:4].str.upper()"
      ],
      "id": "748cdafd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# `apply`\n",
        "`apply` is very similar to `map`, but for `DataFrame`. The default setting is to go through each column of a `DataFrame`, and the input is the column. You may use the argument `axis=1` to change it to go through each row. Please see the following example. \n",
        "\n",
        "::: {#exm-}"
      ],
      "id": "472958a5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "data = pd.DataFrame(np.random.rand(4, 4),\n",
        "                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n",
        "                    columns=['one', 'two', 'three', 'four'])\n",
        "data"
      ],
      "id": "f46371cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "f = lambda x: x.max() - x.min()\n",
        "\n",
        "data.apply(f)"
      ],
      "id": "dae6da04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change `axis` to find the range for each row."
      ],
      "id": "8f878bd6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.apply(f, axis=1)"
      ],
      "id": "4def7962",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "We can use more complicated function to get more complicated result.\n",
        "\n",
        "::: {#exm-}"
      ],
      "id": "16878992"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = pd.DataFrame(np.random.rand(4, 4),\n",
        "                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n",
        "                    columns=['one', 'two', 'three', 'four'])\n",
        "\n",
        "f = lambda x: pd.Series([x.max(), x.min()], index=['max', 'min'])\n",
        "\n",
        "data.apply(f)"
      ],
      "id": "ed7e7ca9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Some examples\n",
        "\n",
        "\n",
        "::: {#exm-}\n",
        "Consider the following DataFrame."
      ],
      "id": "113d1ed6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.DataFrame({'location': ['East', 'East', 'East', 'East',\n",
        "                                'West', 'West', 'West', 'West'],\n",
        "                   'data': np.random.randn(8)},\n",
        "                   index=['Ohio', 'New York', 'Vermont', 'Florida',\n",
        "                          'Oregon', 'Nevada', 'California', 'Idaho'])\n",
        "df.loc[['Vermont', 'Nevada', 'Idaho'], 'data'] = np.nan\n",
        "df"
      ],
      "id": "4b66f171",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We would like to fill in NA values with the mean from each `location` group.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "# Tips"
      ],
      "id": "40a87e2f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "df.groupby('location', group_keys=False).apply(lambda x: x.fillna(x.mean()))"
      ],
      "id": "3cf01dc2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The argument `group_keys=False` refers to the setting whether you want to `group_keys` to be presented. If it is `True`, the result looks like this."
      ],
      "id": "2e3013c1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "df.groupby('location', group_keys=True).apply(lambda x: x.fillna(x.mean()))"
      ],
      "id": "76083056",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "We could also fill in NA values with predefined values, similar to the non-groupby case.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "# Tips"
      ],
      "id": "0a981336"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "predefined = {'East': 0.1, 'West': -0.5}\n",
        "df.groupby('location', group_keys=True).apply(lambda x: x.fillna(predefined[x.name]))"
      ],
      "id": "364f1f5b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "# Chaining commands\n",
        "You may chain commands to a `DataFrame`, just like the examples shown above. If the commands are too long:\n",
        "\n",
        "- a `()` has to be used to indicate that this is a multiline command, and\n",
        "- the line is broken before the `.` sybmol.\n",
        "\n",
        "Please see the following example."
      ],
      "id": "e4a80fe7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(df.groupby('location', group_keys=False)\n",
        "    .apply(lambda x: x.fillna(predefined[x.name]))\n",
        "    .reset_index()\n",
        "    .groupby('location')\n",
        "    .max()\n",
        ")"
      ],
      "id": "5542c180",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!-- ### Sorting and Ranking\n",
        "\n",
        "- `.sort_values(by=)`\n",
        "- `.rank(ascending=, method=)` -->\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!-- ### Summarizing and Computing Descriptive Statistics\n",
        "\n",
        "- `sum`, `cumsum`\n",
        "- `mean`, `median`\n",
        "- `.describe()`\n",
        "- `.cov`, `.corr` -->\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!-- ### Reading and Writing Data in Text Format\n",
        "- `read_csv`\n",
        "- `read_excel`\n",
        "- `df.to_csv` -->\n",
        "\n",
        "\n",
        "<!-- ### Copies and views\n",
        "\n",
        "- `inplace` -->\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Read and write files\n",
        "\n",
        "### Read files\n",
        "\n",
        "In most cases we will read data from a `csv` file or an `excel` file. \n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# Read `csv` files\n",
        "A `csv` file is a plain txt file, with a fixed format. It consists of rows and columns. Rows are separated by newline symbol, which is usually `\\n`. Columns are separated by a separator. Common separators include empty spaces` `, comma `,`, semi-column `;`, tab space `\\t`. There might be other speical separators, depending on the creators of the specific `csv` files. \n",
        "\n",
        "In `pandas`, you may use `pd.read_csv()` function to read a `csv` file. \n",
        "\n",
        "1. The argument `sep` is used to set separators. The default is `,`.\n",
        "2. The argument `names` is used to set the column names. Otherwise the column names will be generated and is highly unlikely to be directly usable.\n",
        "3. The argument `header` will choose the header row and only parse the lines after it. If there is no header, you may set `header=None`.\n",
        "4. The argument `index_col` is used to set the index column(s). If it is `False`, the index will be automatically generated from `0`. If it is set to a list of columns, the result will be a multi-index system.\n",
        "\n",
        "You may read the [document](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) for more arguments.\n",
        "\n",
        "Please see the following example.\n",
        "\n",
        "::: {#exm-}\n",
        "The file is [`yob1880.txt`](assests/datasets/yob1880.txt). This is from the US Baby names dataset. It provides the counts of each US baby names born in 1880. You may use any txt editor to open the file. The first few rows are like the following:\n",
        "\n",
        "```\n",
        "Mary,F,7065\n",
        "Anna,F,2604\n",
        "Emma,F,2003\n",
        "Elizabeth,F,1939\n",
        "Minnie,F,1746\n",
        "Margaret,F,1578\n",
        "```\n",
        "It seems that `sep` is the default `,`. So you may directly directly read it into a `DataFrame` by `pd.read_csv()`."
      ],
      "id": "56b22e39"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('assests/datasets/yob1880.txt')\n",
        "df.head()"
      ],
      "id": "e7fcbd81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please look at the header of the `DataFrame`. It is supposed to be the first data. Therefore there is no header in the original file. So the correct way to read the file is "
      ],
      "id": "763ca7c1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('assests/datasets/yob1880.txt',\n",
        "                 header=None,\n",
        "                 names=['Name', 'Sex', 'Counts'])\n",
        "df.head()"
      ],
      "id": "0bb8d807",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "# Read Excel files\n",
        "`pandas` provides `pd.read_excel()` function to read Excel files. Since Excel files are much more complicated than `csv` files, it requires more setting. One of the most important different setting is the engine. `pandas` needs you to specify a way (an engine) to understand Excel files. For the newer Excel file `.xlsx`, it is recommended to use the engine `openpyxl`. \n",
        "\n",
        "If you don't have `openpyxl` installed, you may use the following code to install it.\n",
        "\n",
        "```{.bash}\n",
        "pip install openpyxl\n",
        "```\n",
        "\n",
        "Many options, like `header`, `names` and `index_col`, are very similar to `pd.read_csv()`. Some additional remarks:\n",
        "\n",
        "1. There is no `sep` argument since columns are not separated based on separators.\n",
        "2. The argument `sheet_name` is used to choose which sheet(s) you want to read.\n",
        "3. The argument `nrows` is used to set the number of rows to parse.\n",
        "\n",
        "You may read the [document](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html) for more arguments.\n",
        "\n",
        "\n",
        "::: {#exm-}\n",
        "The file can be downloaded from [here](assests/datasets/prepost.xlsx). This is the result of the Pre-Post test of a class for the course COURSE1001. You may first use Microsoft Office or other spreadsheet applications to open the file to have some ideas what it look like. \n",
        "\n",
        "Here is the screenshot of the first few columns. `Last` and `First` refers to the last name and the first name of the student, while `Last0X` and `First0X` are students' fake names.\n",
        "\n",
        "![](assests/img/20230212225803.png)  \n",
        "\n",
        "Note that this files contains two `DataFrame`s. \n",
        "\n",
        "- The first is the result of the pretest, which is from row 3 to row 11, with the header row 2. \n",
        "- The second is the result of the posttest, which is from row 15 to row 23, with the header row 14. \n",
        "To read the file, the code is as follows:\n"
      ],
      "id": "e970cea2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_pre = pd.read_excel('assests/datasets/prepost.xlsx',\n",
        "                       engine='openpyxl',\n",
        "                       header=2, \n",
        "                       nrows=10)\n",
        "df_pre "
      ],
      "id": "bf1b68fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_post = pd.read_excel('assests/datasets/prepost.xlsx',\n",
        "                        engine='openpyxl',\n",
        "                        header=14,\n",
        "                        nrows=10)                      \n",
        "df_post"
      ],
      "id": "008c0183",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems that the original files have an additional column `Unnamed: 13` containing `nan` values that should be dropped. Then it is not necessary to read it from the original file. Here we could use the argument `usecols` to select the first 13 columns. We only show the example of pretest result.\n"
      ],
      "id": "2b5961ac"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_pre = pd.read_excel('assests/datasets/prepost.xlsx',\n",
        "                       engine='openpyxl',\n",
        "                       header=2, \n",
        "                       nrows=10,\n",
        "                       usecols=list(range(13)))\n",
        "df_pre "
      ],
      "id": "a99c55fb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "### Write files\n",
        "\n",
        "We will only talk about writing in `csv`. The function is `df.to_csv()`. It is straightforward.\n",
        "\n",
        "- The argument `index` is used to control whether you want to write index into the file. The default is `True`. If the index doesn't contain any real information, we usually set it to be `False`.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Example: Movies\n",
        "\n",
        "Below we explore the MovieLens 1M datasets. You may download it from this [link](assests/datasets/movies.dat). This is a `.dat` file, and you may use the following code to read it into a `DataFrame`."
      ],
      "id": "83e6a839"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "mnames = ['movie_id', 'title', 'genres']\n",
        "movies = pd.read_table('assests/datasets/movies.dat', sep='::',\n",
        "                       header=None, names=mnames, engine=\"python\",\n",
        "                       encoding='ISO-8859-1')\n",
        "movies.head()"
      ],
      "id": "8b92019a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example we concentrate on exploring the genres information. We first want to find all genres in this dataset. The idea is:\n",
        "\n",
        "- split each item in the `genres` column by `|` to get a list.\n",
        "- go through each item in the `genres` column, and union all lists together.\n",
        "\n",
        "This can be done by the `map` function.\n",
        "\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "# Tips"
      ],
      "id": "a7c9bdf0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "all_genres = list()\n",
        "movies['genres'].map(lambda x: all_genres.extend(x.split('|')))"
      ],
      "id": "c593fb4b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`all_genres` is the list of all genres (with duplicates).\n",
        "\n",
        "In the output of the above code you may see many `None` in each row. This is because the lambda function used in `map` doesn't have a return value. However after applying the function to each row, new genres information is added to the list `all_genres`.\n",
        ":::\n",
        "\n",
        "Then we would like to drop all the duplicates to get the list of all unique genres.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "# Tips"
      ],
      "id": "cbdeb555"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "genres = pd.unique(all_genres)\n",
        "genres"
      ],
      "id": "cf874a10",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`genres` is the list of all unique genres.\n",
        ":::"
      ],
      "id": "530f694c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| eval: false\n",
        "all_genres = list()\n",
        "movies['genres'].map(lambda x: all_genres.extend(x.split('|')))\n",
        "\n",
        "genres = pd.unique(all_genres)\n",
        "\n",
        "dummies = pd.DataFrame(np.zeros((len(movies), len(genres))), columns=genres)\n",
        "\n",
        "for i, gen in enumerate(movies.genres):\n",
        "    indices = dummies.columns.get_indexer(gen.split('|'))\n",
        "    dummies.iloc[i, indices] = 1\n",
        "\n",
        "movies_windic = movies.join(dummies.add_prefix('Genre_'))"
      ],
      "id": "79f0a276",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "Many problems are based on @Pra2018a.\n",
        "\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "Let `df` be a `DataFrame`. Please answer the following questions in a Markdown cell.\n",
        "\n",
        "1. What does `df[0]` do?\n",
        "2. What does `df[[0]]` do?\n",
        "3. What does `df[0:1]` do?\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "Please use the following code to generate a series `ser`, and then finish the following tasks."
      ],
      "id": "111ec5f1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
        "myarr = np.arange(26)\n",
        "mydict = dict(zip(mylist, myarr))\n",
        "ser = pd.Series(mydict)"
      ],
      "id": "0cbbe126",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Convert the series `ser` into a dataframe `df` with its index as another column on the dataframe.\n",
        "2. Pick the two columns of `df` and set them into two serieses `ser1` and `ser2`. \n",
        "3. Combine two series `ser1` and `ser2` to form a new dataframe `newdf`, and name their columns `ser1` and `ser2`.\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "Consider two serieses `ser1` and `ser2`. You may use the following `ser1` and `ser2` as an example. The output of each questions below should be a series. You may want to learn the following commands:\n",
        "\n",
        "- [`np.union1d()`](https://numpy.org/doc/stable/reference/generated/numpy.union1d.html)\n",
        "- [`np.intersect1d()`](https://numpy.org/doc/stable/reference/generated/numpy.intersect1d.html)\n",
        "- [`np.isin()`](https://numpy.org/doc/stable/reference/generated/numpy.isin.html)"
      ],
      "id": "d0c1175b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
        "ser2 = pd.Series([4, 5, 6, 7, 8])"
      ],
      "id": "40f488e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Find all the elements from `ser1` that are also in `ser2`.\n",
        "2. Find all the elements from `ser2` that are also in `ser1`.\n",
        "3. From `ser1` remove items present in `ser2`.\n",
        "4. Find the union of `ser1` and `ser2`.\n",
        "5. Find the intersection of `ser1` and `ser2`.\n",
        "6. Find all the elemetns that are in either `ser1` or `ser2`, but not both.\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "Consider the following `DataFrame`."
      ],
      "id": "71fd121f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
        "                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n",
        "                    columns=['one', 'two', 'three', 'four'])"
      ],
      "id": "f44ebc36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Please select the column `two`.\n",
        "2. Please select the second and the third row.\n",
        "3. Please find the rows that the column `three` value is bigger than `5`.\n",
        "4. Please find the last row that the column `three` value is bigger than `5`.\n",
        "5. Please find the rows that the column `three` value is bigger than `5`, and display the resulted `DataFrame` with only `Colorado` and `Utah` row and `four` and `one` columns, in the specified order.\n",
        ":::\n",
        "\n",
        "\n",
        "<!-- \n",
        "::: {#exr-}\n",
        "## Some statistics\n",
        "Please check the following commands and answer the following questions.\n",
        "\n",
        "- [`np.percentile()`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html)\n",
        "\n",
        "How to get the minimum, 25th percentile, median, 75th, and max of a numeric series? You may use the following Series as an example."
      ],
      "id": "f859587b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "ser = pd.Series(np.random.normal(10, 5, 25))"
      ],
      "id": "4c04657b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: -->\n",
        "\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "Consider the following `Series`.\n"
      ],
      "id": "563bacd1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))"
      ],
      "id": "86d9528f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Please use `pd.Series.value_counts()` to calculte the frequency counts of each unique value of the following Series.\n",
        "2. Please keep the top 2 most frequent items of `ser` as it is and replace everything else as `Other`.\n",
        ":::\n",
        "\n",
        "<!-- \n",
        "::: {#exr-}\n",
        "Please keep the top 2 most frequent items of `ser` as it is and replace everything else as `Other`."
      ],
      "id": "b0e28218"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))"
      ],
      "id": "c08df13d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: -->\n",
        "\n",
        "<!-- \n",
        "::: {#exr-}\n",
        "Please use `pd.cut` or `pd.qcut` to bin the Series `ser` into 10 equal deciles. You may use the following `ser` as an example."
      ],
      "id": "1bb6706e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "ser = pd.Series(np.random.random(20))"
      ],
      "id": "7747e9bc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: -->\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "Consider the Series `ser`:"
      ],
      "id": "e8d27160"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "ser = pd.Series(np.random.randint(1, 10, 7))"
      ],
      "id": "a9dde79b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find the positions of numbers that are multiples of 3 from ser.\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "Compute the mean of `weights` of each `fruit`."
      ],
      "id": "a78dffbb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
        "weights = pd.Series(np.linspace(1, 10, 10))\n",
        "df = pd.DataFrame({'fruit': fruit, 'weights': weights})"
      ],
      "id": "dc6ee999",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "Consider the following DataFrame. "
      ],
      "id": "db043c09"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
      ],
      "id": "ea6fa336",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Check if `df` has any missing values.\n",
        "2. Please count the number of missing values in each column.\n",
        "3. Please replace all missing values in `Min.Price` and `Max.Price` with their mean respectively.\n",
        "\n",
        "<!-- 3. In the original DataFrame, please replace the missing values in `Min.Price` with the column's mean and those in `Max.Price` with the column's median. -->\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!-- \n",
        "::: {#exr-}\n",
        "Replace the spaces in `my_str = 'dbc deb abed gade'` with the least frequent character.\n",
        "::: -->\n",
        "<!-- \n",
        "\n",
        "::: {#exr-}\n",
        "Suppress scientific notations like `e-03` in `df` and print up to 4 numbers after decimal."
      ],
      "id": "b6fa177d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.DataFrame(np.random.random(4)**10, columns=['random'])\n",
        "df"
      ],
      "id": "5cc1bd83",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: -->\n",
        "\n",
        "<!-- \n",
        "::: {#exr-}\n",
        "Format the values in column `random` of `df` as percentages."
      ],
      "id": "423102c3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
        "df"
      ],
      "id": "b2900ace",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: -->\n",
        "\n",
        "<!-- \n",
        "::: {#exr-splitacolumnofadf}\n",
        "`table3` can be downloaded from [here](assests/datasets/table3.csv). Please use the following code to get the `DataFrame`."
      ],
      "id": "c84e5038"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "table3 = pd.read_csv('assests/datasets/table3.csv', index_col='Unnamed: 0')\n",
        "table3['newrate'] = table3['rate'].str.split('/')"
      ],
      "id": "e1ba0c54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please read cases and populations from the column `newrate` and write them into columns to make the original `table3` tidy.\n",
        "::: -->\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "Get the last two rows of `df` whose row sum is greater than 100."
      ],
      "id": "02a8196e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))"
      ],
      "id": "1bca50c9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "The groupby object `df_grouped` is given below."
      ],
      "id": "95749c05"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
        "                   'price': np.random.rand(9),\n",
        "                   'taste': np.random.randint(0, 11, 9)})\n",
        "\n",
        "df_grouped = df.groupby(['fruit'])"
      ],
      "id": "4a55e674",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Get the group belonging to `apple` as a DataFrame.\n",
        "2. Find the second largest value of `taste` for `banana`.\n",
        "3. Compute the mean `price` for every `fruit`.\n",
        ":::\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "\n",
        "Join `df1` and `df2` by `fruit`/`pazham` and `weight`/`kilo`."
      ],
      "id": "adc42f1d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
        "                    'weight': ['high', 'medium', 'low'] * 3,\n",
        "                    'price': np.random.randint(0, 15, 9)})\n",
        "\n",
        "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
        "                    'kilo': ['high', 'low'] * 3,\n",
        "                    'price': np.random.randint(0, 15, 6)})"
      ],
      "id": "f1319e94",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "Consider the following DataFrame."
      ],
      "id": "bc3eb0fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])"
      ],
      "id": "52190eb1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Replace `NaN` with string `missing` in columns `Manufacturer`, `Model` and `Type`.\n",
        "2. Create an index as a combination of these three columns.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "Given the following DataFrame."
      ],
      "id": "551064ea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'name': ['James', 'Jane', 'Melissa', 'Ed', 'Neil'],\n",
        "    'age': [30, 40, 32, 67, 43],\n",
        "    'score': ['90%', '95%', '100%', '82%', '87%'],\n",
        "    'age_missing_data': [30, 40, 32, 67, None],\n",
        "    'income':[100000, 80000, 55000, 62000, 120000]\n",
        "})"
      ],
      "id": "5bb1c029",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Please use `.map` to create a new column `numeric_score` whose value is the number version of `score`. \n",
        "- Please use `.apply` to create a new column `numeric_score` whose value is the number version of `score`. \n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {#exr-}\n",
        "The following DataFrame is given."
      ],
      "id": "2b9bcbc7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame([\"STD, City    State\",\n",
        "                   \"33, Kolkata    West Bengal\",\n",
        "                   \"44, Chennai    Tamil Nadu\",\n",
        "                   \"40, Hyderabad    Telengana\",\n",
        "                   \"80, Bangalore    Karnataka\"],\n",
        "                   columns=['row'])"
      ],
      "id": "de70bfaa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please create a new DataFrame out of `df` by spliting it into three columns based on `,` and four spaces. In addition, the column names of the new DataFrame are given by the first row of `df`.\n",
        ":::\n"
      ],
      "id": "fbf515b1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "base",
      "language": "python",
      "display_name": "base"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}